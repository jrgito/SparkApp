app {
  config {
    name: "spider-horizontalization"
    spark: {
      "spark.master" = "local"
      "spark.driver.memory" = "2g"
      "spark.executor.memory" = "1g"
      "spark.total.executor.cores" = "2"
      "spark.cores.max" = "2"
    }
    defaultTable: {
      path: ${?SCHEMA}"/data/master/sfma/"${?PROCESS}
      format: "parquet"
      mode: "overwrite"
      pks: []
      includePartitionsAsPk: true
      sortPks: false
      partitionColumns: [closing_date]
      properties: {
        readerOptions: {}
        writerOptions: {}
      }
    }
    hdfs: {
      enable: false
//      enable: ${?HDFS}
      properties: {}
    }
    options: {
      debug: true
      debug: ${?DEBUG}
    }
  }
  tables: [
    {
      name: "table1"
      path: ${?SCHEMA}"/data/master/sfma/parametrics/"${?PROCESS}
      pks: [horizontal, vertical, catalogsf_product_id]
      partitionColumns: []
      fileType: "csv"
    }
    {
      name: "table2"
      pks: [country_id, entity_id, customer_id, business_area_id, year_number]
    }
    {
      name: "table3"
      pks: [country_id, entity_id, customer_id, business_area_id, year_number]
    }
  ]
  process: {
   table1 : table1
  }
}